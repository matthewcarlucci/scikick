---
title: Merge
---

# Introduction

The blood is probably the most well-studied tissue in the single-cell field, mostly because everything is already dissociated "for free".
Of particular interest has been the use of single-cell genomics to study cell fate decisions in haematopoeisis.
Indeed, it was not long ago that dueling interpretations of haematopoeitic stem cell (HSC) datasets were a mainstay of single-cell conferences.
Sadly, these times have mostly passed so we will instead entertain ourselves by combining a small number of these datasets into a single analysis.

# Data loading

```{r, results='asis', echo=FALSE}
sce.nest <- readRDS("output/nestorowa_normalization_sce.RDS") 
dec.nest <- readRDS("output/nestorowa_normalization_dec.RDS")
```

```{r}
sce.nest
```

The Grun dataset requires a little bit of subsetting and re-analysis to only consider the sorted HSCs.

```{r, results='asis', echo=FALSE}
sce.grun.hsc <- readRDS("output/grun_quality_control_sce.RDS")
```

```{r}
library(scuttle)
sce.grun.hsc <- sce.grun.hsc[,sce.grun.hsc$protocol=="sorted hematopoietic stem cells"]
sce.grun.hsc <- logNormCounts(sce.grun.hsc)

set.seed(11001)
library(scran)
dec.grun.hsc <- modelGeneVarByPoisson(sce.grun.hsc) 
```

Finally, we will grab the Paul dataset, which we will also subset to only consider the unsorted myeloid population.
This removes the various knockout conditions that just complicates matters.

```{r, results='asis', echo=FALSE}
sce.paul <- readRDS("output/paul_quality_control_sce.RDS")
```

```{r}
sce.paul <- sce.paul[,sce.paul$Batch_desc=="Unsorted myeloid"]
sce.paul <- logNormCounts(sce.paul)

set.seed(00010010)
dec.paul <- modelGeneVarByPoisson(sce.paul) 
```

# Setting up the merge

```{r common-annotation}
common <- Reduce(intersect, list(rownames(sce.nest),
    rownames(sce.grun.hsc), rownames(sce.paul)))
length(common)
```

Combining variances to obtain a single set of HVGs.

```{r variance-modelling}
combined.dec <- combineVar(
    dec.nest[common,], 
    dec.grun.hsc[common,], 
    dec.paul[common,]
)
hvgs <- getTopHVGs(combined.dec, n=5000)
```

Adjusting for gross differences in sequencing depth.

```{r normalization}
library(batchelor)
normed.sce <- multiBatchNorm(
    Nestorowa=sce.nest[common,],
    Grun=sce.grun.hsc[common,],
    Paul=sce.paul[common,]
)
```

# Merging the datasets

We turn on `auto.merge=TRUE` to instruct `fastMNN()` to merge the batch that offers the largest number of MNNs.
This aims to perform the "easiest" merges first, i.e., between the most replicate-like batches,
before tackling merges between batches that have greater differences in their population composition.

```{r batch-correction}
set.seed(1000010)
merged <- fastMNN(normed.sce, subset.row=hvgs, auto.merge=TRUE)
```

Not too much variance lost inside each batch, hopefully.
We also observe that the algorithm chose to merge the more diverse Nestorowa and Paul datasets before dealing with the HSC-only Grun dataset.

```{r}
metadata(merged)$merge.info[,c("left", "right", "lost.var")]
```

```{r, echo=FALSE}
# Sanity check that it does in fact do that.
ref <- metadata(merged)$merge.info[1,c("left", "right")]
stopifnot(all.equal(sort(unname(unlist(unlist(ref)))), c("Nestorowa", "Paul")))
```

```{r export}
saveRDS(merged,"output/merged_sce.RDS")
```

